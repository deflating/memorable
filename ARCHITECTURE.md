# Memorable â€” Architecture

Persistent memory system for Claude Code. Automatically captures session transcripts, generates summaries, extracts a knowledge graph, and makes everything searchable â€” all running on-device with Apple ML frameworks.

## How It Fits Together

```
Claude Code Session
    â”‚
    â”œâ”€ SessionStart hook â”€â”€â†’ Load startup seed (sacred facts, recent sessions)
    â”‚
    â”œâ”€ UserPromptSubmit hook â”€â”€â†’ Capture + embed user messages (Apple NLEmbedding)
    â”‚
    â”œâ”€ PostToolUse hook â”€â”€â†’ Queue tool calls for async processing
    â”‚     â”‚
    â”‚     â””â”€ [async every 30s] ObservationProcessor
    â”‚           â”œâ”€ Generate deterministic observation (no LLM)
    â”‚           â”œâ”€ Embed with Apple NLEmbedding (512-dim)
    â”‚           â””â”€ KG extraction: afm candidates â†’ Sonnet filter â†’ store
    â”‚
    â”œâ”€ PreCompact hook â”€â”€â†’ Remind to save important context
    â”‚
    â””â”€ Stop hook â”€â”€â†’ Generate session-level summary from observations
         â”‚
         â””â”€ [async, when transcript idle 15m] TranscriptProcessor
               â”œâ”€ LLMLingua-2 compression at 50%
               â”œâ”€ Apple AFM: emoji header tags
               â”œâ”€ Apple AFM: session note (~100 words)
               â””â”€ Store in sessions table
```

## Directory Layout

```
memorable/
â”œâ”€â”€ plugin/
â”‚   â”œâ”€â”€ .mcp.json                    # MCP server config â†’ spawns `python3 -m server --watch`
â”‚   â”œâ”€â”€ .claude-plugin/
â”‚   â”‚   â””â”€â”€ plugin.json              # Plugin metadata (name, version, description)
â”‚   â”œâ”€â”€ pyproject.toml               # Dependencies: llmlingua, watchdog, libsql-experimental
â”‚   â”‚
â”‚   â”œâ”€â”€ server/                      # Core application
â”‚   â”‚   â”œâ”€â”€ __main__.py              # CLI: 5 modes (mcp, watch, watcher, process, init)
â”‚   â”‚   â”œâ”€â”€ config.py                # Loads ~/.memorable/config.json
â”‚   â”‚   â”œâ”€â”€ db.py                    # SQLite/libSQL database layer
â”‚   â”‚   â”œâ”€â”€ mcp_server.py            # MCP JSON-RPC server with 7 tools
â”‚   â”‚   â”œâ”€â”€ processor.py             # Transcript â†’ compressed â†’ summary pipeline
â”‚   â”‚   â”œâ”€â”€ observer.py              # Tool calls â†’ observations + embeddings
â”‚   â”‚   â”œâ”€â”€ kg.py                    # Knowledge graph extraction (afm + NLTagger + Sonnet)
â”‚   â”‚   â”œâ”€â”€ llm.py                   # Claude CLI wrapper (Sonnet via `claude -p`)
â”‚   â”‚   â”œâ”€â”€ web.py                   # HTTP server for web viewer
â”‚   â”‚   â”œâ”€â”€ watcher.py               # File watcher + background processing loop
â”‚   â”‚   â””â”€â”€ import_sessions.py       # Legacy session note importer
â”‚   â”‚
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”œâ”€â”€ hooks.json               # 5 lifecycle hook definitions
â”‚   â”‚   â””â”€â”€ scripts/
â”‚   â”‚       â”œâ”€â”€ session_start.py     # â†’ stdout injected as context
â”‚   â”‚       â”œâ”€â”€ user_prompt.py       # â†’ capture + embed
â”‚   â”‚       â”œâ”€â”€ post_tool_use.py     # â†’ queue for async processing
â”‚   â”‚       â”œâ”€â”€ session_stop.py      # â†’ generate session summary
â”‚   â”‚       â””â”€â”€ pre_compact.py       # â†’ advisory reminder
â”‚   â”‚
â”‚   â”œâ”€â”€ ui/
â”‚   â”‚   â””â”€â”€ viewer.html              # Web UI (dark theme, tabs, KG graph)
â”‚   â”‚
â”‚   â”œâ”€â”€ skills/                      # Claude Code skill definitions
â”‚   â””â”€â”€ commands/                    # Command metadata
â”‚
â””â”€â”€ reprocess.py                     # Batch reprocessing script
```

## Database Schema

**Location:** `~/.memorable/memorable.db`

### sessions
Processed session records with compressed transcripts and LLM-generated summaries.

| Column | Type | Description |
|--------|------|-------------|
| transcript_id | TEXT UNIQUE | JSONL filename stem |
| date | TEXT | Session date (YYYY-MM-DD) |
| title | TEXT | Extracted from first substantive user message |
| summary | TEXT | AFM-generated ~100-word session note |
| header | TEXT | Emoji tags: `ðŸ”§ Built auth \| âœ… Chose JWT` |
| compressed_50 | TEXT | LLMLingua-2 at 50% â€” searchable archive |
| source_path | TEXT | Original JSONL path |
| message_count | INTEGER | Total messages in session |
| word_count | INTEGER | Total words |
| human_word_count | INTEGER | Words from user only |

### observations
Tool usage events with deterministic descriptions and 512-dim embeddings.

| Column | Type | Description |
|--------|------|-------------|
| session_id | TEXT | Claude Code session ID |
| observation_type | TEXT | discovery, change, bugfix, feature, refactor, decision, session_summary |
| title | TEXT | e.g. "Edited server/kg.py" |
| summary | TEXT | Deterministic description from tool metadata |
| files | TEXT | JSON array of file paths touched |
| embedding | BLOB | float32 512-dim from Apple NLEmbedding |
| tool_name | TEXT | Read, Edit, Write, Bash, Grep, etc. |

### observations_queue
Pending tool calls waiting for async processing.

| Column | Type | Description |
|--------|------|-------------|
| session_id | TEXT | Session that generated this |
| tool_name | TEXT | Which tool was called |
| tool_input | TEXT | Tool arguments (truncated) |
| tool_response | TEXT | Tool output (truncated to 3000 chars) |
| context_before | TEXT | Last assistant message (~500 chars) |
| context_after | TEXT | Last user message (~500 chars) |
| status | TEXT | pending â†’ processed \| skipped |

### kg_entities
Knowledge graph nodes.

| Column | Type | Description |
|--------|------|-------------|
| name | TEXT | Entity name (e.g. "React", "Matt Kennelly") |
| type | TEXT | person, project, technology, organization, file, concept, tool, service, language |
| priority | INTEGER | 10=sacred, 7-9=important, 4-6=contextual, 1-3=ephemeral |
| description | TEXT | Optional description |
| metadata | TEXT | JSON blob |

UNIQUE constraint on (name, type).

### kg_relationships
Knowledge graph edges.

| Column | Type | Description |
|--------|------|-------------|
| source_id | INTEGER | FK â†’ kg_entities |
| target_id | INTEGER | FK â†’ kg_entities |
| rel_type | TEXT | uses, builds, created, owns, depends_on, part_of, works_with, configured_in, deployed_on, related_to |
| confidence | REAL | Default 1.0 |

### user_prompts
Captured user messages with embeddings for semantic search.

| Column | Type | Description |
|--------|------|-------------|
| session_id | TEXT | Session ID |
| prompt_number | INTEGER | Sequence within session |
| prompt_text | TEXT | User's message (system-reminder blocks stripped) |
| embedding | BLOB | float32 512-dim |

### processing_queue
Transcript processing queue (deduplication via file hash).

| Column | Type | Description |
|--------|------|-------------|
| transcript_path | TEXT | Full path to JSONL |
| file_hash | TEXT UNIQUE | MD5[:12] for dedup |
| status | TEXT | pending â†’ done \| error |
| error | TEXT | Error message if failed |

## MCP Tools

The MCP server exposes 7 tools to Claude Code:

### memorable_get_startup_seed
Returns sacred facts (priority 10), important entries (7-9), and recent session summaries. Called automatically by the SessionStart hook.

### memorable_search_sessions
Keyword search over session titles, compressed transcripts, and summaries. Returns matching sessions with title, date, header, and preview.

### memorable_search_observations
Hybrid semantic + keyword search. Embeds the query via Apple NLEmbedding, computes cosine distance against stored embeddings (threshold < 0.6), combines with keyword matches. Score = 0.7 Ã— (1 - distance) + 0.3. Searches both observations and user prompts.

### memorable_get_observations
List observations for a specific session or recent across all sessions.

### memorable_record_significant
Manually save important moments to the KG as entities. Accepts description, optional entity name, type, and priority (1-10). Priority 10 = sacred (immutable on update).

### memorable_query_kg
Query the knowledge graph by entity name, type, or minimum priority. Returns entities with their relationships formatted as `entity â†’ [rel_type] â†’ target`.

### memorable_get_system_status
System health: session count, KG entity count, pending queue, total words processed, config summary.

## Pipelines

### Transcript Processing
**File:** `server/processor.py`

```
JSONL transcript (idle 15+ min)
    â†“
Validate: â‰¥15 messages, â‰¥100 human words
    â†“
Skip: autonomous wakeup sessions (< 5% human words)
    â†“
Format conversation as "Matt: ... / Claude: ..." text
    â†“
LLMLingua-2 compress at 50% (force-preserve: \n ** : . ? !)
    â†“
Apple AFM â†’ emoji header (first 800 words of compressed)
    â†“
Apple AFM â†’ session note (first/last 1800 words of raw)
    â†“
Extract title from first substantive human message
    â†“
Store in sessions table
```

**Model:** LLMLingua uses `microsoft/llmlingua-2-bert-base-multilingual-cased-meetingbank` (~500MB, loaded once, runs on CPU).

**Session notes** are generated by Apple's on-device Foundation Model (~3B params). Quality is limited â€” this is the first target for replacement by an MLX fine-tuned model.

### Observation Generation
**File:** `server/observer.py`

No LLM involved. Observations are built deterministically from tool metadata:

| Tool | Example Output |
|------|---------------|
| Read | "Read server/kg.py (lines 100-200)" |
| Edit | "Replaced 'old_code' with 'new_code' in kg.py" |
| Write | "Wrote server/llm.py (90 lines)" |
| Bash | Uses Claude's `description` field, or extracts primary command |
| Grep | "Searched for 'pattern' (42 matches in server/)" |
| Glob | "Found files matching '*.py' (8 files)" |
| WebFetch | "Fetched example.com" |
| WebSearch | "Searched web for 'query'" |

Each observation is embedded via Apple NLEmbedding (512-dim float32) and stored with its session ID, files touched, and observation type.

### Knowledge Graph Extraction
**File:** `server/kg.py`

Three-tier extraction followed by a Sonnet quality filter:

```
Observation text
    â†“
Tier 1: NLGazetteer â€” instant lookup of known entities (feedback loop)
    â†“
Tier 2: Apple AFM â€” extract candidate entities + relationships as JSON
    â†“
Tier 3: Apple NLTagger â€” catch person/org names AFM missed
    â†“
Batch all candidates across observations, deduplicate
    â†“
ONE Sonnet call via claude CLI: filter real entities from garbage
    â†“
Store approved entities (priority 4) + relationships
    â†“
Rebuild gazetteer (new entities become future lookup targets)
```

**Why Sonnet for filtering:** AFM (~3B) can't reliably distinguish real named entities from code artifacts. SQL fragments, variable names, CLI commands, and file paths all slip through. The blocklist approach was unsustainable. Sonnet gets one tiny call per batch (~20 entity names, ~7 seconds) and perfectly separates real from garbage.

**Why not Sonnet for everything:** Usage limits. The KG filter is a tiny prompt (a few hundred tokens). Session notes would require sending full transcripts â€” too expensive per session.

### Search
**File:** `server/mcp_server.py` (memorable_search_observations)

Hybrid approach combining keyword and semantic search:

1. **Keyword pass:** SQL LIKE queries on observation title/summary and prompt text
2. **Semantic pass:** Embed query via Apple NLEmbedding, compute cosine distance against all stored embeddings, threshold at distance < 0.6
3. **Scoring:** `score = 0.7 Ã— (1 - cosine_distance) + 0.3 Ã— keyword_boost`
4. **Merge:** Deduplicate, rank by score, return top N

Searches both observations and user_prompts in a single call.

## CLI Modes

**Entry point:** `python3 -m server [flags]`

| Flag | Mode | Description |
|------|------|-------------|
| *(none)* | MCP server | JSON-RPC over stdio, no watcher |
| `--watch` | MCP + watcher | Normal operation: MCP server + background file watcher |
| `--watcher` | Watcher only | Standalone daemon (for launchd), no MCP |
| `--process` | Process once | Scan, queue, process all pending transcripts, then exit |
| `--init` | Initialize | Create config + database, then exit |

Production: `--watch` is the default, spawned by Claude Code via `.mcp.json`.

## Web Viewer

**File:** `server/web.py` + `ui/viewer.html`

```bash
python3 -m server.web --port 7777
```

### API Endpoints

| Route | Params | Returns |
|-------|--------|---------|
| `/` | â€” | HTML UI |
| `/api/stats` | â€” | Session count, KG stats, words processed |
| `/api/sessions` | `limit`, `q` | Recent or filtered sessions |
| `/api/session` | `id` | Session detail + observations + prompts |
| `/api/timeline` | `limit` | Mixed observations + prompts, chronological |
| `/api/observations` | `limit`, `session_id` | Observation list |
| `/api/prompts` | `limit`, `session_id`, `q` | User messages |
| `/api/search` | `q`, `limit` | Unified search (observations + prompts) |
| `/api/kg` | `min_priority` | Graph data: nodes + edges |

### UI
- Dark theme, gold accent (#f0c000)
- Four tabs: Sessions, Observations, Knowledge Graph, Timeline
- Force-directed canvas graph for KG visualization (pan/zoom/drag/hover)
- Frosted glass header, skeleton loading states, staggered card animations
- Cmd+K search focus, responsive at 768px

## Configuration

**File:** `~/.memorable/config.json`

```json
{
  "memory_dir": "~/claude-memory",
  "db_path": "~/.memorable/memorable.db",
  "transcript_dirs": ["~/.claude/projects"],

  "sync_url": "",
  "sync_auth_token": "",

  "compression_rate_storage": 0.50,

  "watcher_enabled": true,
  "stale_minutes": 15,
  "min_messages": 15,
  "min_human_words": 100,

  "seed_session_count": 10,
  "live_capture_interval": 20,

  "observer_enabled": true,
  "observer_max_tool_output": 3000,
  "observer_process_interval": 30
}
```

## LLM Interface

**File:** `server/llm.py`

Thin wrapper around the `claude` CLI. Uses Claude Code's existing subscription â€” no separate API key.

```python
call_llm(prompt, system="...", max_tokens=1024) â†’ str
call_llm_json(prompt, system="...") â†’ dict | None
```

Runs `claude -p --model sonnet --system-prompt "..." --no-session-persistence` from `/tmp` (to avoid picking up CLAUDE.md). Timeout: 180 seconds.

Currently used only for KG entity filtering. Designed as a single swap point â€” when an MLX fine-tuned model is ready, change this one file.

## Dependencies

### Python (pyproject.toml)
- `llmlingua>=0.2` â€” Prompt compression (MeetingBank BERT model, ~500MB)
- `watchdog>=3.0` â€” Cross-platform file system monitoring
- `libsql-experimental>=0.0.50` â€” SQLite with embedded replica support

### System
- macOS (required for Apple ML frameworks)
- Python 3.10+
- `afm` CLI â€” Apple Foundation Model
- `claude` CLI â€” For Sonnet entity filtering
- PyObjC â€” Bridge to NaturalLanguage.framework (NLEmbedding, NLTagger, NLGazetteer)

## Technology Stack

| Component | Technology | On-Device? |
|-----------|-----------|-----------|
| Compression | LLMLingua-2 (BERT) | Yes |
| Session summaries | Apple AFM (~3B) | Yes |
| Observations | Rule-based extraction | Yes |
| Embeddings | Apple NLEmbedding (512-dim) | Yes |
| Named entities | Apple NLTagger (NameType) | Yes |
| Entity candidates | Apple AFM | Yes |
| Entity gazetteer | Apple NLGazetteer | Yes |
| Entity filtering | Claude Sonnet (via CLI) | API call |
| Database | SQLite / libSQL | Yes |
| Web UI | Vanilla HTML/CSS/JS | Yes |
| File watching | watchdog | Yes |

Everything runs locally except the Sonnet entity filter, which makes one small API call per observation batch.

## Future: MLX Fine-Tuned Model

Session notes are the first replacement target. The plan:

1. Collect training data from existing DeepSeek-quality session notes
2. Fine-tune Qwen3-4B (or similar) via `mlx-lm` LoRA on Apple Silicon
3. Fuse adapters into standalone model
4. Swap into `llm.py` â€” replaces Sonnet for KG filtering too
5. Fully on-device, zero API cost, better quality than AFM

The M4 Mac Mini (24GB) can run a 4B model at ~40-70 tok/s in 4-bit quantization. Fine-tuning with QLoRA needs ~3-4GB.
